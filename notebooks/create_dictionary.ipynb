{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание словаря для symspell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь на основе справочников профессий HH.RU и общероссийского классификатора занятий [ОК 010-2014 (МСКЗ-08)](https://data.mos.ru/classifier/7710168515-obshcherossiyskiy-klassifikator-zanyatiy?pageNumber=58&versionNumber=1&releaseNumber=1). Русскоязычная версия [ISCO08](https://esco.ec.europa.eu/en/classification/occupation_main).\n",
    "\n",
    "Для каждого слова внесем в словарь все словоформы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dkharitonov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dkharitonov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "download('punkt')\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src import drop_stopwords, tokenize_drop_punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MA = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco08 = pd.read_csv('../datasets/external/ok-010-2014_ISCO-08_ru.csv', encoding = 'cp1251', sep=';')\n",
    "roles = pd.read_csv('../datasets/external/hh_prof_roles.csv')\n",
    "specialities = pd.read_csv('../datasets/external/hh_prof_specializations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morh_analyse(word: str) -> list:\n",
    "    result = []\n",
    "\n",
    "    phrase = MA.parse(word)[0]\n",
    "    tag = phrase.tag\n",
    "    if 'LATN' in tag:\n",
    "        result = [word]\n",
    "    else:\n",
    "        result = [p.word for p in phrase.lexeme]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "text = (isco08.NAME.to_list() \n",
    "        + roles.category_name.to_list() \n",
    "        + roles.prof_name.to_list()\n",
    "        + specialities.category_name.to_list()\n",
    "        + specialities.prof_name.to_list())\n",
    "\n",
    "for sentence in text:\n",
    "    tokens = drop_stopwords(tokenize_drop_punkt(sentence))\n",
    "    for token in tokens:\n",
    "        docs += morh_analyse(token)\n",
    "\n",
    "dictionary = pd.Series(docs, name='term').value_counts().reset_index(level=0)\n",
    "dictionary.columns = ['term', 'count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим словарь профессий со словарем symspell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "symdict = pd.read_csv('../models/symspell/ru-100k.txt', sep=' ', header=0)\n",
    "symdict.columns = ['term', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = symdict.merge(dictionary, how='outer', on='term', suffixes=('sym', 'prof'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict.countsym.fillna(0, inplace=True)\n",
    "merged_dict.countprof.fillna(0, inplace=True)\n",
    "merged_dict['countprof'] *= 45000\n",
    "merged_dict['count'] = (merged_dict['countsym'] + merged_dict['countprof']).astype('int')\n",
    "merged_dict.drop(['countsym', 'countprof'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict.sort_values(by='count', ascending=False).to_csv('../models/symspell/professions.txt', sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=3, prefix_length=7)\n",
    "dictionary_path = '../models/symspell/professions.txt'\n",
    "sym_spell.load_dictionary(dictionary_path, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_term = 'инжинер'\n",
    "suggestions = sym_spell.lookup(input_term, Verbosity.CLOSEST, include_unknown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "инженер, 1, 25\n"
     ]
    }
   ],
   "source": [
    "for suggestion in suggestions:\n",
    "    print(suggestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Мы создали и сохранили словарь для исправления опечаток в названиях профессий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ac6f7dda0a387060d6c296a1a992241c48e02a04b69f2209e2d27f192d44adcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
